\documentclass[format=sigplan,review=false,screen=true]{acmart}\settopmatter{}

\usepackage[para]{footmisc}   %% gather footnotes on a single line

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{supertabular}
\usepackage{stmaryrd}
\usepackage{color}
\usepackage{multirow}
\usepackage{calc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{xspace}
\usepackage{dashrule}  % for \hdashrule
\usepackage{stackrel}
\usepackage{enumerate}
\usepackage{framed}
\usepackage{bussproofs}
\usepackage{mdframed}  % highlight
\usepackage{hyperref}
\usepackage{comment}
%\usepackage{natbib}
\usepackage{ifthen}
\usepackage{pdftexcmds}

\usepackage{mathpartir}
\usepackage{ottalt}

\usepackage{fancyvrb}

\usepackage{listings}
\lstset{language=Haskell}

%\special{papersize=8.5in,11in}
%\setlength{\pdfpageheight}{\paperheight}
%\setlength{\pdfpagewidth}{\paperwidth}

%\usepackage{palatino}
\renewcommand{\familydefault}{\rmdefault}
%\renewcommand{\ttdefault}{cmtt}

%% Show admissible premises in rules
%% This should be false in main body of text and true in the appendix.
\newif\ifadmissible
\admissiblefalse
\newcommand\suppress[1]{\ifadmissible{[#1]}\else{}\fi}
\inputott{ett-rules}


\newcommand{\alt}{\ |\ }
\newcommand{\rul}[1]{\rref{#1}}


\newcommand{\fc}{DC\xspace}
\newcommand{\fimp}{D\xspace}
\newcommand{\pico}{\textsc{PiCo}\xspace}


\newif\ifcomments
\commentstrue
\ifcomments
\newcommand{\scw}[1]{\textcolor{blue}{{SCW: #1}}}
\newcommand{\rae}[1]{\textcolor{magenta}{{RAE: #1}}}
\newcommand\av[1]{\textcolor{orange}{{AV: #1}}}
\else
\newcommand{\scw}[1]{}
\newcommand{\rae}[1]{}
\newcommand\av[1]{}
\fi




%% allow more interline spacing (and fewer overfull hboxes).
\tolerance=5000

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission
%\setcopyright{none}             %% For review submission
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}


%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%% Note: author/year citations are required for papers published as an
%% issue of PACMPL.
\citestyle{acmauthoryear}   %% For author/year citations

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}


\title{A specification of eta-equivalence in LNrep}

\author{Stephanie Weirich}
\orcid{0000-0002-6756-9168}
\affiliation{
  \position{Professor}
  \department{Computer and Information Science}              %% \department is recommended
  \institution{University of Pennsylvania}            %% \institution is required
  \streetaddress{3330 Walnut St}
  \city{Philadelphia}
  \state{PA}
  \postcode{19104}
  \country{USA}
}
\email{sweirich@cis.upenn.edu}

\author{Antoine Voizard}
\affiliation{
  \position{}
  \department{}              %% \department is recommended
  \institution{University of Pennsylvania}            %% \institution is required
  \streetaddress{}
  \city{}
  \state{}
  \postcode{}
  \country{USA}
}
\email{voizard@seas.upenn.edu}

\author{Anastasiya Kravchuk-Kirilyuk}
\affiliation{
  \position{}
  \department{}              %% \department is recommended
  \institution{University of Pennsylvania}            %% \institution is required
  \streetaddress{}
  \city{}
  \state{}
  \postcode{}
  \country{USA}
}
\email{akravc@sas.upenn.edu}

\begin{abstract}

The Corespec project is an extensive mechanization in Coq of the metatheory of
System D and System DC, two related, dependently-typed languages aimed at
replacing the GHC's internal language, Core~\cite{ghc}. In this talk, we take
a retrospective look at our development through the lens of a recent addition,
$\eta$-equivalence. In particular, we describe our experience with the
practical application of locally nameless variable-binding representation for
mechanized metatheory, supported by the Ott and LNgen tools.
\end{abstract}

\maketitle

%% Our running head is too long for acmsmall
\renewcommand{\shortauthors}{Weirich, Voizard, Kravchuk-Kirilyuk}

\section{Corespec}
The idea behind the Corespec project is to provide a replacement for GHC's
Core language FC~\cite{fc} that supports full spectrum dependent
types~\cite{Weirich:systemd} .  Specifically, this project required untangling
the notions of type on the one hand and of erasable component (computationally
irrelevant) on the other - which current GHC essentially conflates.

As part of this process, the Corespec project developed two related
dependently-typed languages: System D and System DC. The former is Curry-style
and includes only computationally relevant information in its syntax; the
latter includes much more: typing annotations, irrelevant arguments, and
coercions in support of decidable type checking. As these annotations are
complex, the implicit language provides an uncluttered specification of the
semantics of the language as well as an simplified context for certain parts
of the metatheory.

We have shown that these two languages are related via annotation and erasure
theorems. That means that our progress result about System D can be translated
to System DC through the first theorem, and the preservation result of System
DC can be similarly translated to System D via the second.

Our Coq formalization has been invaluable both in the confidence that it gives
us in our results, but also in the design of the system in the first
place. Although Systems D and DC draw on prior
work~\cite{eisenberg:phd,gundry:phd,weirich:dwk}, we designed this language in
conjunction with its mechanization.

After completing the initial design, which we reported in ICFP 2017, we have
been extending the equational theory with rules for $\eta$-equivalence. For
this part of the project, we have been joined by Kravchuk-Kirilyuk who did not
participate in the original design.

\av{Potential ideas: the "breaking the design + recompiling" methodology}

\scw{We need to explain much more precisely about what definitions are
  provided by Ott, what lemmas are provided by
  lngen, and what we actually proved.  maybe pick some representative
  lemmas such as confluence to state?}

\subsection{Tool support for Locally Nameless representation}
Our formalization of Systems D and DC uses a locally nameless representation
for variable binding, and employs co-finite
quantification~\cite{aydemir:popl-binders} in the rules that manipulate
binders.

Our choice was strongly influenced by the availability of two tools:

The first, Ott~\cite{Ott}, is a specification tool for programming languages
semantics. One can think of it as a compiler for its specification language.
It takes as input rules of the shape as shown below \av{ref} - that is, an
user-definable ascii representation of the syntax, judgment and rules of the
language. It outputs a representation of it in another format - for instance,
\LaTeX, or Coq with a locally-nameless representation (abbreviated Coq/LN in
the following). \av{bad sentence}.

For example, when using Ott for a simplified version of the language (here
simply the $\lambda$-calculus), one obtains the following inductive type to
represent the syntax:
\begin{verbatim}
Induction exp :=
   | var_f : atom -> exp
   | var_b : nat -> exp
   | abs   : exp -> exp
   | app   : exp -> exp -> exp
\end{verbatim}
As expected, we get a locally nameless representation: variables have 2
constructors, one for bound variables that uses a de Bruijn representation,
and another for free variables that relies on a set of names (\verb!atom!).

Ott also translates rule specifications of inductive definitions to a Coq
inductive datatype.  For instance, rule \av{refs} XXXX as show in figure XXXX
gets compiled to the case XXXX shown in figure XXXXX (this is a constructor of
the inductive type that ott defines to represent the reduction judgment). Ott
also automatically defines operations for free variable calculation (called
|fv|, free variable substitution (called |subst|) and bound variable
substitution (called |open|).

The second tool, LNgen~\cite{aydemir:lngen}, is a complement to Ott when used
to output Coq/LN.  This tool uses the same specification to derive additional
definitions and helper lemmas about the Coq/LN code that Ott generated.  For
instance, \av{What? Should we mention close?}  In almost any reasoning about
LN terms, these lemmas keep the proofs manageable and high-level. \av{Not
  great}

For example, one lemma generated by LNgen asserts that
\begin{verbatim}
Lemma subst_fresh :
   forall x, x `notin` fv e -> subst x e = e.
\end{verbatim}

\section{Case study: Eta reduction}
One part of extending Systems D and DC with eta-eqivalence rules requires
proving the confluence of a parallel reduction system extended with rules for
\emph{eta-reduction}. This confluence proof justifies the consistency of the
type equivalence rules of our language and is the main component of our
canonical forms theorem.

Our Ott specification of this rule, in ASCII syntax, appears in Figure
\ref{fig:ott-eta}.
\begin{figure}[h]
\begin{verbatim}
 |- b => b'
 a = b x
----------------------------- :: Eta
 |- \ x. a => b'
\end{verbatim}
\caption{Ott input for rule Eta}
\label{fig:ott-eta}
\end{figure}

At first glance, this rule seems a bit strange. What has become of the
free variable condition (\verb|x `notin` fv b|)  required by Eta-reduction?

When we look at the generated Coq definition, it is also not immediately
obvious that \verb|x| is not allowed to appear in \verb|b|. Here is the
here is the case (constructor)
generated for the $\eta$ rule above:
\begin{verbatim}
Par_Eta : forall (L:vars) (a b b' : Exp),
  Par b b' ->
  (forall x, x notin L -> open a x = app b x) ->
  Par (abs a) b'
\end{verbatim}
This rule is on constructor of the \verb|Par| inductive type that specifies
the parallel reduction relation \verb! |= b => b'!.  This rule also relies on
co-finite quantification: the second premise generalizes over the complement
of \verb!L!, an universally quantified finite set. This quantification means
that the induction hypothesis generated by this rule is available for an
infinite number of variables chosen for the binder --- all except those in
\verb|L|. Furthermore, it is in this quantification that enforces the free variable
condition. Because \verb|b| is quantified at the outer most level of the type, it
cannot depend on the variable \verb|x|.

With this reasoning, we can see why the original Ott definition makes sense.
The free variable condition \emph{is} actually enforced, although somewhat
indirectly. Notice that, in the conclusion, $[[a]]$ appears under the
binder. This prompts Ott to output a definition in which $[[x]]$ can appear in
$[[a]]$, as it is aware that $\lambda$ is a binder.  Now, notice the second
premise of the rule - in particular the fact that no side of the equation is
under a binder. This means that in the definition generated by Ott, $[[x]]$
can \emph{not} appear in $[[b]]$. This results in the proper semantics for
this rule.


Although the cofinite  version of the rule generates a strong induction hypothesis, sometimes one
might want an \emph{existential} version for constructing derivations that
mention a particular name for the bound variable:
\begin{verbatim}
Lemma Par_Eta_exists : forall a b b' x,
  x `notin` fv b -> x `notin` fv b' ->
  Par b b' ->
  open a x = app b x ->
  Par (abs a) b'
\end{verbatim}
This is a version of the rule we prove is admissible in our development. Not
only this is a more useful form of the rule for some cases, but this is also a
great way to check that we indeed defined the \av{semantics? system?
  language?}  that we intended. Note that this rule makes the free variable
conditions explicit.

Finally, we have also proven one more version of the eta-reduction rule. This
version relies on the \verb|close| operation that replaces a free variable
\verb|x| with a bound variable, suitable for \verb|abs|.
\begin{verbatim}
Lemma Par_Eta_close : forall a b x,
  x `notin` fv a ->
  Par a b ->
  Par (abs (close x (app a (var_f x)))) b
\end{verbatim}
This version is perhaps the ``most obviously correct'' version of
$\eta$-reduction with this representation. However, it is the least useful in
proof development. It is not really handy for backward reasoning, since rewriting the
term in the conclusion to have this specific shape might take quite a bit of reasoning. However, it is convenient for forward reasoning
(especially since $[[a]]$ may in some cases be a term of the shape \verb!open (...)!, and
Lngen provides several lemmas to easily rewrite interactions of \verb!open! and \verb!close!), and it is also
a good check on the meaning of what we're defining. \av{bad writing...}

\section{Lessons learned}
Overall, we have been very happy with the use of Coq and the related tools
for our development. In particular, the mechanization of
Systems D and DC has made it easier to include new collaborators when
considering extensions of the system. In this case, KK could make progress on
this task without having to understand the entire development.

Furthermore, we also appreciated the confidence that Coq provides in our
reasoning. For example, our initial design of our $\eta$-equivalence rule
dependend on the following inversion lemma, which sadly, does not hold in
System D, for subtle reasons.
\begin{lemma}[Inversion]
if $[[G |= \x.b x : Pi x : A.B ]]$ and $[[ x `notin` fv b]]$ then $[[ G |= b :
Pi x:A.B ]]$.
\end{lemma}
The lemma fails because the erased language only mentions variables in
computationally relevant positions. However, we could have used x implicitly,
such as in instantiating a polymorphic function.

Because this lemma doesn't hold, our untyped parallel reduction relation does
not have the preservation property. The rule above allows the term to reduce,
in some cases to an ill-typed term.  However, none of the rest of the
metatheory relies on preservation for parallel reduction---and we can verify
that easily with our existing proof development.



\bibliography{../icfp17/weirich.bib,../icfp17/proposal.bib,../icfp17/rae.bib,coqpl.bib}

\end{document}




%% Local Variables:
%% mode: LaTeX
%% End:

%%  LocalWords:  interline overfull hboxes papersize FL Ahmed eir sweirich HM
%%  LocalWords:  Hamidhasan taun SCW lncs urgh app rccll damas milner HMV SB
%%  LocalWords:  Damas's outsidein SB's ghc Expr normalizePoly normalizeProxy
%%  LocalWords:  normalizeExpr TypeApplications AllowAmbiguousTypes APIs API
%%  LocalWords:  ICFP Refl SCond MonadReader MonadWriter RAE polytype const
%%  LocalWords:  NB SwapPair swapPair sP HM's monotypes Barendregt Gen InstG
%%  LocalWords:  monotype vars InstS hmv Abs TApp Var V's Annot algv foo DAbs
%%  LocalWords:  RankNTypes metatheorems skolemization inst'd DeepSkol Skol
%%  LocalWords:  Twelf Dreyer Blume's ML's DK Neel Krishnaswami Didier hlio
%%  LocalWords:  TypeOperators DataKinds PolyKinds ConstraintKinds Typeable
%%  LocalWords:  ScopedTypeVariables woozle boolCast eqT unsafeThe Val Cond
%%  LocalWords:  eval SExpr sEval SBool SVal sIf Inst IFPOP ListInst infixr
%%  LocalWords:  STrue SFalse supertype checkIf myId myAbs abs Num GHCi ghci
%%  LocalWords:  fromInteger myPair MkG pr Ty forall ol pid cc hm sp inst gen
%%  LocalWords:  sb dn pf sf ys xs se
